{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04a18ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import logging\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bc60f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9fe5f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Fingerprint not found. Saved model loading will continue.\n",
      "INFO:absl:path_and_singleprint metric could not be logged. Saved model loading will continue.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained SRGAN model from TensorFlow Hub\n",
    "srgan_module = hub.load(\"https://tfhub.dev/captain-pool/esrgan-tf2/1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4ca8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and upscale frames\n",
    "def upscale_frame(frame):\n",
    "    frame = cv2.resize(frame, (224, 224))  # Resize to the model's input size\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    frame = frame / 255.0  # Normalize pixel values\n",
    "\n",
    "    # Ensure the input is of type tf.float32\n",
    "    frame = tf.convert_to_tensor(frame, dtype=tf.float32)\n",
    "\n",
    "    frame = tf.expand_dims(frame, axis=0)  # Add batch dimension\n",
    "    upscaled_frame = srgan_module(frame, training=False)  # Use the pre-trained model for upscaling\n",
    "    upscaled_frame = tf.squeeze(upscaled_frame, axis=0)  # Remove batch dimension\n",
    "    upscaled_frame = tf.clip_by_value(upscaled_frame, 0, 1)  # Clip values to [0, 1]\n",
    "    upscaled_frame = tf.image.convert_image_dtype(upscaled_frame, dtype=tf.uint8)  # Convert to uint8\n",
    "    upscaled_frame = tf.image.encode_png(upscaled_frame)  # Encode as PNG\n",
    "    upscaled_frame = tf.image.decode_png(upscaled_frame)  # Decode from PNG\n",
    "    upscaled_frame = tf.image.convert_image_dtype(upscaled_frame, dtype=tf.uint8)  # Convert to uint8\n",
    "    return upscaled_frame.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86ecac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a video file\n",
    "def process_video(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    logging.info(f\"Total frames in the video: {total_frames}\")\n",
    "\n",
    "    temp_folder = 'temp_frames'\n",
    "    os.makedirs(temp_folder, exist_ok=True)\n",
    "\n",
    "    frame_count = 0\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                logging.info(\"End of video reached.\")\n",
    "                break\n",
    "\n",
    "            logging.info(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "\n",
    "            try:\n",
    "                upscaled_frame = upscale_frame(frame)\n",
    "\n",
    "                # Denoise the frame\n",
    "                upscaled_frame = cv2.fastNlMeansDenoisingColored(\n",
    "                    upscaled_frame,\n",
    "                    None,  # Use default denoising parameters\n",
    "                    h=5,    # Filter strength\n",
    "                    hColor=5\n",
    "                )\n",
    "\n",
    "                # Save the upscaled and denoised frame to a temporary file\n",
    "                temp_frame_path = os.path.join(temp_folder, f\"frame_{frame_count:04d}.png\")\n",
    "                cv2.imwrite(temp_frame_path, cv2.cvtColor(upscaled_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error in processing frame: {e}\")\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "        # Use ffmpeg to concatenate frames into a video\n",
    "        ffmpeg_cmd = (\n",
    "            f\"ffmpeg -framerate {fps} -i {temp_folder}/frame_%04d.png \"\n",
    "            f\"-c:v libx264 -pix_fmt yuv420p {output_path}\"\n",
    "        )\n",
    "        subprocess.run(ffmpeg_cmd, shell=True, check=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during video processing: {e}\")\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        logging.info(\"Cleaning up temporary files.\")\n",
    "        # Remove temporary frame files\n",
    "        for file_name in os.listdir(temp_folder):\n",
    "            file_path = os.path.join(temp_folder, file_name)\n",
    "            os.remove(file_path)\n",
    "        os.rmdir(temp_folder)\n",
    "        logging.info(\"Processing video completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c23489f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Total frames in the video: 36\n",
      "INFO:root:Processing frame 0/36\n",
      "INFO:root:Processing frame 1/36\n",
      "INFO:root:Processing frame 2/36\n",
      "INFO:root:Processing frame 3/36\n",
      "INFO:root:Processing frame 4/36\n",
      "INFO:root:Processing frame 5/36\n",
      "INFO:root:Processing frame 6/36\n",
      "INFO:root:Processing frame 7/36\n",
      "INFO:root:Processing frame 8/36\n",
      "INFO:root:Processing frame 9/36\n",
      "INFO:root:Processing frame 10/36\n",
      "INFO:root:Processing frame 11/36\n",
      "INFO:root:Processing frame 12/36\n",
      "INFO:root:Processing frame 13/36\n",
      "INFO:root:Processing frame 14/36\n",
      "INFO:root:Processing frame 15/36\n",
      "INFO:root:Processing frame 16/36\n",
      "INFO:root:Processing frame 17/36\n",
      "INFO:root:Processing frame 18/36\n",
      "INFO:root:Processing frame 19/36\n",
      "INFO:root:Processing frame 20/36\n",
      "INFO:root:Processing frame 21/36\n",
      "INFO:root:Processing frame 22/36\n",
      "INFO:root:Processing frame 23/36\n",
      "INFO:root:Processing frame 24/36\n",
      "INFO:root:Processing frame 25/36\n",
      "INFO:root:Processing frame 26/36\n",
      "INFO:root:Processing frame 27/36\n",
      "INFO:root:Processing frame 28/36\n",
      "INFO:root:Processing frame 29/36\n",
      "INFO:root:Processing frame 30/36\n",
      "INFO:root:Processing frame 31/36\n",
      "INFO:root:Processing frame 32/36\n",
      "INFO:root:Processing frame 33/36\n",
      "INFO:root:Processing frame 34/36\n",
      "INFO:root:Processing frame 35/36\n",
      "INFO:root:End of video reached.\n",
      "INFO:root:Cleaning up temporary files.\n",
      "INFO:root:Processing video completed.\n"
     ]
    }
   ],
   "source": [
    "# Process the input video and save the output in MP4 format\n",
    "input_video_path = r'C:\\Users\\91748\\Downloads\\happy.mp4'  # Replace with the actual path\n",
    "output_video_path = r'C:\\Users\\91748\\Downloads\\lli.mp4'  # Replace with the desired output path\n",
    "\n",
    "process_video(input_video_path, output_video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
